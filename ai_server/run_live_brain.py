import torch
from transformers import AutoModelForVision2Seq, AutoProcessor
from PIL import Image
import numpy as np
import cv2
import os
import time

# Gereksiz uyarƒ±larƒ± kapat
os.environ["USE_TF"] = "NO"
os.environ["USE_JAX"] = "NO"

def start_live_intelligence():
    print("üöÄ Sƒ∞STEM BA≈ûLATILIYOR: Canlƒ± Yapay Zeka Modu")
    
    # 1. Cihaz Ayarlarƒ±
    device = "mps" if torch.backends.mps.is_available() else "cpu"
    print(f"üíª ƒ∞≈ülemci: {device} (Metal Performance Shaders)")

    # 2. Model Y√ºkleme
    model_id = "openvla/openvla-7b"
    print("üß† Model RAM'e y√ºkleniyor (L√ºtfen bekleyin)...")
    
    try:
        processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)
        model = AutoModelForVision2Seq.from_pretrained(
            model_id, 
            torch_dtype=torch.bfloat16, 
            low_cpu_mem_usage=True, 
            trust_remote_code=True
        ).to(device)
        print("‚úÖ BEYƒ∞N HAZIR!")
    except Exception as e:
        print(f"‚ùå Kritik Model Hatasƒ±: {e}")
        return

    # 3. Kamera Ba≈ülatma (SDK yerine Standart Driver)
    print("üëÅÔ∏è Kamera baƒülanƒ±yor...")
    # RealSense genellikle 1 veya 2 numaradadƒ±r. √ñnce 1'i dene.
    cap = cv2.VideoCapture(3) 
    
    # USB y√ºk√ºn√º hafifletmek i√ßin √ß√∂z√ºn√ºrl√ºƒü√º sabitliyoruz
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    
    if not cap.isOpened():
        print("‚ö†Ô∏è Kamera 1 bulunamadƒ±, 0 deneniyor...")
        cap = cv2.VideoCapture(2)
        if not cap.isOpened():
            print("‚ùå HATA: Hi√ßbir kamera bulunamadƒ±!")
            return

    print("üöÄ CANLI AKI≈û BA≈ûLADI! (√áƒ±kƒ±≈ü i√ßin 'q' basƒ±n)")

    try:
        while True:
            # 1. Kare Yakala
            ret, frame = cap.read()
            if not ret:
                print("‚ö†Ô∏è Kare atlandƒ±...")
                time.sleep(0.1)
                continue

            # 2. G√∂r√ºnt√ºy√º ƒ∞≈üle (BGR -> RGB -> PIL)
            # Yapay zeka RGB formatƒ± ister
            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            image_pil = Image.fromarray(image_rgb)
            
            # 3. Beyne G√∂nder (Prompt Hazƒ±rla)
            prompt = "In: What action should the robot take to pick up the object?\nOut:"
            
            # --- KRƒ∞Tƒ∞K VERƒ∞ ƒ∞≈ûLEME (Statik testte doƒüruladƒ±ƒüƒ±mƒ±z y√∂ntem) ---
            inputs = processor(prompt, image_pil, return_tensors="pt")
            
            # S√∂zl√ºƒü√º a√ßƒ±p cihaz ve tip ayarlarƒ±nƒ± yapƒ±yoruz
            inputs = {k: v.to(device) for k, v in inputs.items()}
            inputs["pixel_values"] = inputs["pixel_values"].to(dtype=torch.bfloat16)
            
            # 4. Tahmin Al (Aksiyon Vekt√∂r√º)
            with torch.no_grad():
                # **inputs ile paketi a√ßarak g√∂nderiyoruz (Hata √∂nleyici)
                action = model.predict_action(**inputs, unnorm_key="bridge_orig", do_sample=False)
            
            # 5. Sonucu G√∂rselle≈ütir
            action_raw = action # ƒ∞lk sonucu al
            
            # Terminale Yazdƒ±r
            # Sadece X, Y, Z ve Gripper deƒüerlerini g√∂sterelim (Okunaklƒ± olsun)
            # Format: [X, Y, Z ... Gripper]
            print(f"ü§ñ Hareket: X={action_raw[0]:.3f}, Y={action_raw[1]:.3f}, Z={action_raw[2]:.3f} | Tutma={action_raw[6]:.1f}")
            
            # Ekrana Yazdƒ±r
            text_xyz = f"X: {action_raw[0]:.3f} Y: {action_raw[1]:.3f} Z: {action_raw[2]:.3f}"
            text_grip = f"Gripper: {'AC' if action_raw[6] > 0.5 else 'KAPA'} ({action_raw[6]:.2f})"
            
            # Ye≈üil kutu ve yazƒ±lar
            cv2.rectangle(frame, (10, 10), (350, 80), (0, 0, 0), -1) # Arkaplan
            cv2.putText(frame, text_xyz, (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(frame, text_grip, (20, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
            
            cv2.imshow('OpenVLA Robot Gozu', frame)

            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

    except KeyboardInterrupt:
        print("üõë Durduruluyor...")
    except Exception as e:
        print(f"‚ùå Beklenmedik Hata: {e}")
    finally:
        cap.release()
        cv2.destroyAllWindows()

if __name__ == "__main__":
    start_live_intelligence()